{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 117 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test = pd.read_csv('test.csv', index_col = 0)\n",
    "train = pd.read_csv('train.csv', index_col = 0)\n",
    "# train.head()\n",
    "# train.info()\n",
    "# test.info()\n",
    "### encode values: Sex\n",
    "train.Sex = train.Sex.apply(lambda x: 1 if x=='male' else 0)\n",
    "test.Sex = test.Sex.apply(lambda x: 1 if x=='male' else 0)\n",
    "\n",
    "### impute missing or zero Fare values with median Fares for each Pclass\n",
    "train.loc[(train.Fare==0)&(train.Pclass==1),\"Fare\"] = train[(train['Fare']!=0)]\\\n",
    "                                                                .groupby('Pclass')['Fare'].describe()['50%'][1]\n",
    "train.loc[(train.Fare==0)&(train.Pclass==2),\"Fare\"] = train[(train['Fare']!=0)]\\\n",
    "                                                                .groupby('Pclass')['Fare'].describe()['50%'][2]\n",
    "\n",
    "train.loc[(train.Fare==0)&(train.Pclass==3),\"Fare\"] = train[(train['Fare']!=0)]\\\n",
    "                                                                .groupby('Pclass')['Fare'].describe()['50%'][3]\n",
    "\n",
    "test.loc[((pd.isnull(test['Fare'])==True)|(test.Fare==0))&(test.Pclass==1),\"Fare\"] = train[(train['Fare']!=0)]\\\n",
    "                                                                .groupby('Pclass')['Fare'].describe()['50%'][1]\n",
    "test.loc[((pd.isnull(test['Fare'])==True)|(test.Fare==0))&(test.Pclass==2),\"Fare\"] = train[(train['Fare']!=0)]\\\n",
    "                                                                .groupby('Pclass')['Fare'].describe()['50%'][2]\n",
    "\n",
    "test.loc[((pd.isnull(test['Fare'])==True)|(test.Fare==0))&(test.Pclass==3),\"Fare\"] = train[(train['Fare']!=0)]\\\n",
    "                                                                .groupby('Pclass')['Fare'].describe()['50%'][3]\n",
    "\n",
    "# extract titles from names\n",
    "def title_extractor(row):\n",
    "    return row.split(',')[1].strip().split('.')[0]\n",
    "titles_train = train.Name.apply(title_extractor)\n",
    "titles_test = test.Name.apply(title_extractor)\n",
    "titles_train = titles_train.map({'Mr':'Mr','Mrs':'Mrs','Miss':'Miss','Master':'Master','Dr':'Dr','Rev':'Rev',\n",
    "                                   'Don':'Mr', 'Mlle':'Miss', 'Lady':'Mrs', 'Ms':'Mrs', \n",
    "                                   'Mme':'Mrs', 'the Countess': 'Mrs', 'Col':'Mr','Major':'Mr',\n",
    "                                  'Sir':'Mr','Jonkheer':'Mr','Capt':'Mr'})\n",
    "titles_test = titles_test.map({'Mr':'Mr','Mrs':'Mrs','Miss':'Miss','Master':'Master','Dr':'Dr','Rev':'Rev',\n",
    "                                   'Don':'Mr', 'Mlle':'Miss', 'Lady':'Mrs', 'Ms':'Mrs', \n",
    "                                   'Mme':'Mrs', 'the Countess': 'Mrs', 'Col':'Mr','Major':'Mr',\n",
    "                                  'Sir':'Mr','Jonkheer':'Mr','Capt':'Mr',\n",
    "                              'Dona':'Mrs'})\n",
    "\n",
    "if 'Title' not in train.columns:\n",
    "    train['Title'] = titles_train\n",
    "    title_encoded_train = pd.get_dummies(train.Title, prefix_sep = '_', drop_first = True)\n",
    "    train = pd.concat([train, title_encoded_train], axis = 1)\n",
    "if 'Title' not in test.columns:\n",
    "    test['Title'] = titles_test\n",
    "    title_encoded_test = pd.get_dummies(test.Title, prefix_sep = '_', drop_first = True)\n",
    "    test = pd.concat([test, title_encoded_test], axis = 1)\n",
    "\n",
    "#encode port of embarkation\n",
    "train = pd.concat([train, pd.get_dummies(train.Embarked, prefix_sep = '_', drop_first = True)], axis = 1)\n",
    "test = pd.concat([test, pd.get_dummies(test.Embarked, prefix_sep = '_', drop_first = True)], axis = 1)\n",
    "\n",
    "# add Family size, IsAlone and Has_Cabin\n",
    "\n",
    "train['FamilySize'] = train['Parch'] + train['SibSp'] + 1\n",
    "test['FamilySize'] = test['Parch'] + test['SibSp'] + 1\n",
    "train['IsAlone'] = (train['FamilySize'] == 1).astype(np.int8)\n",
    "test['IsAlone'] = (test['FamilySize'] == 1).astype(np.int8)\n",
    "train['HasCabin'] = train['Cabin'].apply(lambda x: 0 if type(x) == float else 1)\n",
    "test['HasCabin'] = test['Cabin'].apply(lambda x: 0 if type(x) == float else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2         Name\n",
       "7       Ticket\n",
       "9        Cabin\n",
       "10    Embarked\n",
       "11       Title\n",
       "Name: index, dtype: object"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    #categorical columns\n",
    "col_types = train.dtypes.to_frame().reset_index()\n",
    "cat_cols = col_types.loc[col_types[0]=='object']['index']\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train age MSE: 108.90607454508152\n",
      "valid age MSE: 116.78580854916186\n",
      "median age MSE: 236.75963240223462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pavlo\\anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\pavlo\\anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "### ### impute Age by prediction with random forest regressor\n",
    "#y and X sets for Age\n",
    "y_age = train[pd.isnull(train['Age'])==False]['Age']\n",
    "X_age = train[pd.isnull(train['Age'])==False].drop(cat_cols,axis=1).drop(['Age','Survived'],axis=1)\n",
    "\n",
    "#train and val split for Age \n",
    "X_age_train, X_age_val, y_age_train, y_age_val = train_test_split(X_age, y_age, test_size = 0.25, random_state = 21)\n",
    "\n",
    "# select entries with missing Age\n",
    "X_nullage = train[pd.isnull(train['Age'])==True].drop(cat_cols,axis=1).drop(['Age','Survived'],axis=1)\n",
    "\n",
    "# instantiate random forest regressor\n",
    "age_reg = RandomForestRegressor(max_depth=4, random_state=21)\n",
    "age_reg.fit(X_age_train, y_age_train)\n",
    "\n",
    "# predict age for train and val sets\n",
    "y_age_train_pred = age_reg.predict(X_age_train)\n",
    "y_age_val_pred = age_reg.predict(X_age_val)\n",
    "\n",
    "# check mean square erorrs and compare to simple median age imputer\n",
    "print(f'train age MSE: {mean_squared_error(y_age_train, y_age_train_pred)}')\n",
    "print(f'valid age MSE: {mean_squared_error(y_age_val, y_age_val_pred)}')\n",
    "print(f'median age MSE: {mean_squared_error(y_age_val, np.asarray([y_age.median() for i in range(len(y_age_val))]))}')\n",
    "\n",
    "# predict misisng Age values\n",
    "age_imputed = age_reg.predict(X_nullage)\n",
    "# replace null Age with predictions\n",
    "X_nullage['Age'] = age_imputed\n",
    "train.Age.loc[X_nullage['Age'].index] = X_nullage['Age'].copy()\n",
    "\n",
    "### test set age imputation\n",
    "test_nullage = test[pd.isnull(test['Age'])==True].drop(cat_cols,axis=1).drop('Age',axis=1)\n",
    "age_test_imputed = age_reg.predict(test[pd.isnull(test['Age'])==True].drop(cat_cols,axis=1).drop('Age',axis=1))\n",
    "test_nullage['Age'] = age_test_imputed\n",
    "test.Age.loc[test_nullage['Age'].index] = test_nullage['Age'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols.extend(['SibSp', 'Parch'])\n",
    "train = train.drop(cat_cols, axis = 1)\n",
    "test = test.drop(cat_cols, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "SEED = 21 # for reproducibility\n",
    "n_splits = 5 # set folds for out-of-fold prediction\n",
    "kf = KFold(n_splits = n_splits, shuffle = True, random_state=SEED)\n",
    "\n",
    "# Class to extend the Sklearn classifier\n",
    "class SklearnHelper(object):\n",
    "    def __init__(self, clf, seed=21, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        self.clf.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.clf.predict_proba(X)\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        return self.clf.fit(X,y)\n",
    "    \n",
    "    def feature_importances(self,X,y):\n",
    "        print(self.clf.fit(X,y).feature_importances_)\n",
    "    \n",
    "# Class to extend XGboost classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta_features(clf, X_train, y_train, X_test, kf):\n",
    "    '''\n",
    "    stacking using fits on folds to create meta features for test set\n",
    "    '''\n",
    "    \n",
    "    meta_train = np.zeros_like(y_train, dtype=float)\n",
    "    meta_test = np.zeros_like(test.index, dtype=float)\n",
    "    \n",
    "    for i, (train_ind, test_ind) in enumerate(kf.split(X_train, y_train)):\n",
    "        \n",
    "        clf.fit(X_train.iloc[train_ind], y_train.iloc[train_ind]) #fit on train\n",
    "        meta_train[test_ind] = clf.predict_proba(X_train.iloc[test_ind])[:, 1] #create meta features on train\n",
    "        meta_test += clf.predict_proba(X_test)[:, 1] #create meta features on test\n",
    "    \n",
    "    return meta_train, meta_test / kf.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put in our parameters for said classifiers\n",
    "# Random Forest parameters\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 500,\n",
    "     'warm_start': True, \n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features' : 'sqrt',\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Extra Trees Parameters\n",
    "et_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators':500,\n",
    "    #'max_features': 0.5,\n",
    "    'max_depth': 8,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# AdaBoost parameters\n",
    "ada_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate' : 0.75\n",
    "}\n",
    "\n",
    "# Gradient Boosting parameters\n",
    "gb_params = {\n",
    "    'n_estimators': 500,\n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# Support Vector Classifier parameters \n",
    "svc_params = {\n",
    "    'kernel' : 'linear',\n",
    "    'C' : 0.025,\n",
    "    'probability': True,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5 objects that represent our 4 models\n",
    "rf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\n",
    "et = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\n",
    "ada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\n",
    "gb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\n",
    "svc = SklearnHelper(clf=SVC, seed=SEED, params=svc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Numpy arrays of train, test and target ( Survived) dataframes to feed into our models\n",
    "y_train = train['Survived']\n",
    "X_train = train.drop(['Survived'], axis=1)\n",
    "X_test = test.copy() # Creats an array of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pavlo\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "C:\\Users\\pavlo\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "C:\\Users\\pavlo\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
      "C:\\Users\\pavlo\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:359: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is complete\n"
     ]
    }
   ],
   "source": [
    "# Create our OOF train and test predictions. These base results will be used as new features\n",
    "et_oof_train, et_oof_test = get_meta_features(et, X_train, y_train, X_test, kf = kf) # Extra Trees\n",
    "rf_oof_train, rf_oof_test = get_meta_features(rf, X_train, y_train, X_test, kf = kf) # Random Forest\n",
    "ada_oof_train, ada_oof_test = get_meta_features(ada, X_train, y_train, X_test, kf = kf) # AdaBoost \n",
    "gb_oof_train, gb_oof_test = get_meta_features(gb, X_train, y_train, X_test, kf = kf) # Gradient Boost\n",
    "svc_oof_train, svc_oof_test = get_meta_features(svc, X_train, y_train, X_test, kf = kf) # Support Vector Classifier\n",
    "\n",
    "print(\"Training is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>ExtraTrees</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>GradientBoost</th>\n",
       "      <th>SVC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.120591</td>\n",
       "      <td>0.077373</td>\n",
       "      <td>0.497292</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.124649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.985700</td>\n",
       "      <td>0.990899</td>\n",
       "      <td>0.503169</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.884937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.445150</td>\n",
       "      <td>0.544296</td>\n",
       "      <td>0.501150</td>\n",
       "      <td>0.621773</td>\n",
       "      <td>0.761258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.976006</td>\n",
       "      <td>0.985545</td>\n",
       "      <td>0.503348</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.832512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.102511</td>\n",
       "      <td>0.112781</td>\n",
       "      <td>0.498439</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.138896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RandomForest  ExtraTrees  AdaBoost  GradientBoost       SVC\n",
       "0      0.120591    0.077373  0.497292       0.000618  0.124649\n",
       "1      0.985700    0.990899  0.503169       0.999962  0.884937\n",
       "2      0.445150    0.544296  0.501150       0.621773  0.761258\n",
       "3      0.976006    0.985545  0.503348       0.999989  0.832512\n",
       "4      0.102511    0.112781  0.498439       0.000443  0.138896"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_predictions_train = pd.DataFrame( {'RandomForest': rf_oof_train,\n",
    "     'ExtraTrees': et_oof_train,\n",
    "     'AdaBoost': ada_oof_train,\n",
    "      'GradientBoost': gb_oof_train,\n",
    "        'SVC': svc_oof_train\n",
    "    })\n",
    "\n",
    "base_predictions_test = pd.DataFrame( {'RandomForest': rf_oof_test,\n",
    "     'ExtraTrees': et_oof_test,\n",
    "     'AdaBoost': ada_oof_test,\n",
    "      'GradientBoost': gb_oof_test,\n",
    "        'SVC': svc_oof_test\n",
    "    })\n",
    "\n",
    "base_predictions_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_es...\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.8], 'gamma': [0.8],\n",
       "                         'max_depth': [5],\n",
       "                         'min_child_weight': array([1, 3, 5, 7, 9]),\n",
       "                         'n_estimators': [10, 100, 1000], 'nthread': [-1],\n",
       "                         'objective': ['binary:logistic'], 'random_state': [21],\n",
       "                         'scale_pos_weight': [1], 'subsample': [0.8]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm = xgb.XGBClassifier()\n",
    "\n",
    "params_xgb = {\n",
    "    #learning_rate = 0.02,\n",
    " 'n_estimators': [10,100,1000],\n",
    " 'max_depth': [5],\n",
    " 'min_child_weight': np.arange(1,10,2),\n",
    " 'gamma': [0.8],                        \n",
    " 'subsample': [0.8],\n",
    " 'colsample_bytree': [0.8],\n",
    " 'objective': ['binary:logistic'],\n",
    " 'nthread': [-1],\n",
    " 'scale_pos_weight': [1],\n",
    " 'random_state': [21],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(gbm, param_grid=params_xgb, scoring='accuracy', n_jobs = -1, )\n",
    "grid.fit(base_predictions_train, y_train)\n",
    "# predictions = gbm. predict(base_predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.153343</td>\n",
       "      <td>1.17176</td>\n",
       "      <td>0.204428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.00650259</td>\n",
       "      <td>0.249367</td>\n",
       "      <td>0.0260644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.00238814</td>\n",
       "      <td>0.0060039</td>\n",
       "      <td>0.00398583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.00221696</td>\n",
       "      <td>0.0037472</td>\n",
       "      <td>0.00199293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_gamma</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_max_depth</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_n_estimators</th>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_nthread</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_objective</th>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>binary:logistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_random_state</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_scale_pos_weight</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_subsample</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'colsample_bytree': 0.8, 'gamma': 0.8, 'max_d...</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'gamma': 0.8, 'max_d...</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'gamma': 0.8, 'max_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>0.882682</td>\n",
       "      <td>0.877095</td>\n",
       "      <td>0.893855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>0.882022</td>\n",
       "      <td>0.870787</td>\n",
       "      <td>0.876404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>0.910112</td>\n",
       "      <td>0.910112</td>\n",
       "      <td>0.893258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.853933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>0.904494</td>\n",
       "      <td>0.91573</td>\n",
       "      <td>0.898876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>0.887772</td>\n",
       "      <td>0.886655</td>\n",
       "      <td>0.883265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.0180784</td>\n",
       "      <td>0.0222417</td>\n",
       "      <td>0.0165117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       13  \\\n",
       "mean_fit_time                                                    0.153343   \n",
       "std_fit_time                                                   0.00650259   \n",
       "mean_score_time                                                0.00238814   \n",
       "std_score_time                                                 0.00221696   \n",
       "param_colsample_bytree                                                0.8   \n",
       "param_gamma                                                           0.8   \n",
       "param_max_depth                                                         5   \n",
       "param_min_child_weight                                                  9   \n",
       "param_n_estimators                                                    100   \n",
       "param_nthread                                                          -1   \n",
       "param_objective                                           binary:logistic   \n",
       "param_random_state                                                     21   \n",
       "param_scale_pos_weight                                                  1   \n",
       "param_subsample                                                       0.8   \n",
       "params                  {'colsample_bytree': 0.8, 'gamma': 0.8, 'max_d...   \n",
       "split0_test_score                                                0.882682   \n",
       "split1_test_score                                                0.882022   \n",
       "split2_test_score                                                0.910112   \n",
       "split3_test_score                                                0.859551   \n",
       "split4_test_score                                                0.904494   \n",
       "mean_test_score                                                  0.887772   \n",
       "std_test_score                                                  0.0180784   \n",
       "rank_test_score                                                         1   \n",
       "\n",
       "                                                                       14  \\\n",
       "mean_fit_time                                                     1.17176   \n",
       "std_fit_time                                                     0.249367   \n",
       "mean_score_time                                                 0.0060039   \n",
       "std_score_time                                                  0.0037472   \n",
       "param_colsample_bytree                                                0.8   \n",
       "param_gamma                                                           0.8   \n",
       "param_max_depth                                                         5   \n",
       "param_min_child_weight                                                  9   \n",
       "param_n_estimators                                                   1000   \n",
       "param_nthread                                                          -1   \n",
       "param_objective                                           binary:logistic   \n",
       "param_random_state                                                     21   \n",
       "param_scale_pos_weight                                                  1   \n",
       "param_subsample                                                       0.8   \n",
       "params                  {'colsample_bytree': 0.8, 'gamma': 0.8, 'max_d...   \n",
       "split0_test_score                                                0.877095   \n",
       "split1_test_score                                                0.870787   \n",
       "split2_test_score                                                0.910112   \n",
       "split3_test_score                                                0.859551   \n",
       "split4_test_score                                                 0.91573   \n",
       "mean_test_score                                                  0.886655   \n",
       "std_test_score                                                  0.0222417   \n",
       "rank_test_score                                                         2   \n",
       "\n",
       "                                                                       4   \n",
       "mean_fit_time                                                    0.204428  \n",
       "std_fit_time                                                    0.0260644  \n",
       "mean_score_time                                                0.00398583  \n",
       "std_score_time                                                 0.00199293  \n",
       "param_colsample_bytree                                                0.8  \n",
       "param_gamma                                                           0.8  \n",
       "param_max_depth                                                         5  \n",
       "param_min_child_weight                                                  3  \n",
       "param_n_estimators                                                    100  \n",
       "param_nthread                                                          -1  \n",
       "param_objective                                           binary:logistic  \n",
       "param_random_state                                                     21  \n",
       "param_scale_pos_weight                                                  1  \n",
       "param_subsample                                                       0.8  \n",
       "params                  {'colsample_bytree': 0.8, 'gamma': 0.8, 'max_d...  \n",
       "split0_test_score                                                0.893855  \n",
       "split1_test_score                                                0.876404  \n",
       "split2_test_score                                                0.893258  \n",
       "split3_test_score                                                0.853933  \n",
       "split4_test_score                                                0.898876  \n",
       "mean_test_score                                                  0.883265  \n",
       "std_test_score                                                  0.0165117  \n",
       "rank_test_score                                                         3  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_).sort_values(by='rank_test_score', ascending=True)[:3].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9461279461279462"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_train = grid.best_estimator_.predict(base_predictions_train)\n",
    "predictions_test = grid.best_estimator_.predict(base_predictions_test)\n",
    "np.mean(y_train == predictions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Submission File \n",
    "StackingSubmission = pd.DataFrame({ 'PassengerId': test.index,\n",
    "                            'Survived': predictions_test })\n",
    "StackingSubmission.to_csv(\"StackingSubmission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
