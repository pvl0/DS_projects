{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Pclass    891 non-null    int64  \n",
      " 2   Name      891 non-null    object \n",
      " 3   Sex       891 non-null    object \n",
      " 4   Age       714 non-null    float64\n",
      " 5   SibSp     891 non-null    int64  \n",
      " 6   Parch     891 non-null    int64  \n",
      " 7   Ticket    891 non-null    object \n",
      " 8   Fare      891 non-null    float64\n",
      " 9   Cabin     204 non-null    object \n",
      " 10  Embarked  891 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 83.5+ KB\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv', index_col = 0)\n",
    "train = pd.read_csv('train.csv', index_col = 0)\n",
    "# train.head()\n",
    "# train.info()\n",
    "# test.info()\n",
    "train.Embarked.fillna('S', inplace = True)\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 77.5 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2         Name\n",
       "7       Ticket\n",
       "9        Cabin\n",
       "10    Embarked\n",
       "11       Title\n",
       "Name: index, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "### encode values: Sex\n",
    "train.Sex = train.Sex.apply(lambda x: 1 if x=='male' else 0)\n",
    "test.Sex = test.Sex.apply(lambda x: 1 if x=='male' else 0)\n",
    "\n",
    "### impute missing or zero Fare values with median Fares for each Pclass\n",
    "train.loc[(train.Fare==0)&(train.Pclass==1),\"Fare\"] = train[(train['Fare']!=0)]\\\n",
    "                                                                .groupby('Pclass')['Fare'].describe()['50%'][1]\n",
    "train.loc[(train.Fare==0)&(train.Pclass==2),\"Fare\"] = train[(train['Fare']!=0)]\\\n",
    "                                                                .groupby('Pclass')['Fare'].describe()['50%'][2]\n",
    "\n",
    "train.loc[(train.Fare==0)&(train.Pclass==3),\"Fare\"] = train[(train['Fare']!=0)]\\\n",
    "                                                                .groupby('Pclass')['Fare'].describe()['50%'][3]\n",
    "\n",
    "test.loc[((pd.isnull(test['Fare'])==True)|(test.Fare==0))&(test.Pclass==1),\"Fare\"] = train[(train['Fare']!=0)]\\\n",
    "                                                                .groupby('Pclass')['Fare'].describe()['50%'][1]\n",
    "test.loc[((pd.isnull(test['Fare'])==True)|(test.Fare==0))&(test.Pclass==2),\"Fare\"] = train[(train['Fare']!=0)]\\\n",
    "                                                                .groupby('Pclass')['Fare'].describe()['50%'][2]\n",
    "\n",
    "test.loc[((pd.isnull(test['Fare'])==True)|(test.Fare==0))&(test.Pclass==3),\"Fare\"] = train[(train['Fare']!=0)]\\\n",
    "                                                                .groupby('Pclass')['Fare'].describe()['50%'][3]\n",
    "\n",
    "# extract titles from names\n",
    "def title_extractor(row):\n",
    "    return row.split(',')[1].strip().split('.')[0]\n",
    "titles_train = train.Name.apply(title_extractor)\n",
    "titles_test = test.Name.apply(title_extractor)\n",
    "titles_train = titles_train.map({'Mr':'Mr','Mrs':'Mrs','Miss':'Miss','Master':'Master','Dr':'Dr','Rev':'Rare_male',\n",
    "                                   'Don':'Rare_male', 'Mlle':'Miss', 'Lady':'Rare_female', 'Ms':'Mrs', \n",
    "                                   'Mme':'Mrs', 'the Countess': 'Rare_female', 'Col':'Military','Major':'Military',\n",
    "                                  'Sir':'Rare_male','Jonkheer':'Military','Capt':'Military'})\n",
    "titles_test = titles_test.map({'Mr':'Mr','Mrs':'Mrs','Miss':'Miss','Master':'Master','Dr':'Dr','Rev':'Rare_male',\n",
    "                                   'Don':'Rare_male', 'Mlle':'Miss', 'Lady':'Rare_female', 'Ms':'Mrs', \n",
    "                                   'Mme':'Mrs', 'the Countess': 'Rare_female', 'Col':'Military','Major':'Military',\n",
    "                                  'Sir':'Rare_male','Jonkheer':'Military','Capt':'Military',\n",
    "                              'Dona':'Rare_female'})\n",
    "\n",
    "if 'Title' not in train.columns: #to not overwrite the column\n",
    "    train['Title'] = titles_train\n",
    "    title_encoded_train = pd.get_dummies(train.Title, prefix_sep = '_', drop_first = True)\n",
    "    train = pd.concat([train, title_encoded_train], axis = 1)\n",
    "if 'Title' not in test.columns:\n",
    "    test['Title'] = titles_test\n",
    "    title_encoded_test = pd.get_dummies(test.Title, prefix_sep = '_', drop_first = True)\n",
    "    test = pd.concat([test, title_encoded_test], axis = 1)\n",
    "\n",
    "#encode port of embarcation\n",
    "train = pd.concat([train, pd.get_dummies(train.Embarked, prefix_sep = '_', drop_first = True)], axis = 1)\n",
    "test = pd.concat([test, pd.get_dummies(test.Embarked, prefix_sep = '_', drop_first = True)], axis = 1)\n",
    "    \n",
    "# drop columns\n",
    "col_types = train.dtypes.to_frame().reset_index()\n",
    "cat_cols = col_types.loc[col_types[0]=='object']['index']\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(2,30,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train age MSE: 110.57126156943434\n",
      "valid age MSE: 115.06043336656192\n",
      "median age MSE: 236.75963240223462\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### ### impute Age by prediction with random forest regressor\n",
    "#y and X sets for Age\n",
    "y_age = train[pd.isnull(train['Age'])==False]['Age']\n",
    "X_age = train[pd.isnull(train['Age'])==False].drop(cat_cols,axis=1).drop(['Age','Survived'],axis=1)\n",
    "\n",
    "#train and val split for Age \n",
    "X_age_train, X_age_val, y_age_train, y_age_val = train_test_split(X_age, y_age, test_size = 0.25, random_state = 21)\n",
    "\n",
    "# select entries with missing Age\n",
    "X_nullage = train[pd.isnull(train['Age'])==True].drop(cat_cols,axis=1).drop(['Age','Survived'],axis=1)\n",
    "\n",
    "# instantiate random forest regressor\n",
    "    # params = {\n",
    "    #     'max_depth': np.range(10),\n",
    "    #     'min_samples_leaf': np.arange(2,30,2)\n",
    "    # }\n",
    "    # grid_search = GridSearchCV(RandomForestRegressor, params, scoring = 'mean_square_error', cv = 5)\n",
    "# age_reg = RandomForestRegressor(n_estimators = 59, max_depth=4, min_samples_leaf = 7, random_state=21)\n",
    "# age_reg = GradientBoostingRegressor(n_estimators = 50, max_depth=2, min_samples_leaf = 10, random_state=21)\n",
    "age_reg = xgb.XGBRegressor(n_estimators = 25, max_depth=2, random_state=21)\n",
    "age_reg.fit(X_age_train, y_age_train)\n",
    "\n",
    "# predict age for train and val sets\n",
    "y_age_train_pred = age_reg.predict(X_age_train)\n",
    "y_age_val_pred = age_reg.predict(X_age_val)\n",
    "\n",
    "# check mean square erorrs and compare to simple median age imputer\n",
    "print(f'train age MSE: {mean_squared_error(y_age_train, y_age_train_pred)}')\n",
    "print(f'valid age MSE: {mean_squared_error(y_age_val, y_age_val_pred)}')\n",
    "print(f'median age MSE: {mean_squared_error(y_age_val, np.asarray([y_age.median() for i in range(len(y_age_val))]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pavlo\\anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\pavlo\\anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# predict misisng Age values\n",
    "age_imputed = age_reg.predict(X_nullage)\n",
    "# replace null Age with predictions\n",
    "X_nullage['Age'] = age_imputed\n",
    "train.Age.loc[X_nullage['Age'].index] = X_nullage['Age'].copy()\n",
    "\n",
    "### test set age imputation\n",
    "test_nullage = test[pd.isnull(test['Age'])==True].drop(cat_cols,axis=1).drop('Age',axis=1)\n",
    "age_test_imputed = age_reg.predict(test[pd.isnull(test['Age'])==True].drop(cat_cols,axis=1).drop('Age',axis=1))\n",
    "test_nullage['Age'] = age_test_imputed\n",
    "test.Age.loc[test_nullage['Age'].index] = test_nullage['Age'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  index  importance\n",
      "0   Sex    0.215762\n",
      "1    Mr    0.178715\n",
      "2  Fare    0.124783\n",
      "train score: 0.8707865168539326\n",
      "valid score: 0.8156424581005587\n"
     ]
    }
   ],
   "source": [
    "### fitting model\n",
    "X, y = train.drop('Survived', axis = 1), train['Survived']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 21)\n",
    "clf = RandomForestClassifier(max_depth=6, random_state=21)\n",
    "# clf = xgb.XGBClassifier(n_estimators = 75, max_depth = 6, min_samples_leaf = 6, random_state = 21)\n",
    "clf.fit(X_train.drop(cat_cols, axis=1), y_train)\n",
    "\n",
    "feature_importance = pd.DataFrame(clf.feature_importances_, \n",
    "                                  index = X_train.drop(cat_cols, axis=1).columns,\n",
    "                                  columns = ['importance']\n",
    "                                ).sort_values('importance', ascending = False).reset_index()\n",
    "print(feature_importance[:3])\n",
    "# sns.catplot(y='importance', x='index', data = feature_importance, kind = 'bar').set_xticklabels(rotation=45)\n",
    "\n",
    "print(f'train score: {clf.score(X_train.drop(cat_cols, axis=1), y_train)}') #0.83 with mean age imputer\n",
    "print(f'valid score: {clf.score(X_val.drop(cat_cols, axis=1), y_val)}') #0.807175 mean age imputer for max_depth=4\n",
    "                                                                        #0.860986 xgbclassifier\n",
    "test_predictions = clf.predict(test.drop(cat_cols,axis=1))#.drop('Survived',axis=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = test.copy()\n",
    "test_prediction['Survived'] = test_predictions\n",
    "test_prediction['Survived'].to_csv('gender_submission.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
